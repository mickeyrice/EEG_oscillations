{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "590a2e0d",
   "metadata": {},
   "source": [
    "# Slow Osciliations Sleep Challenge - Machine Learning\n",
    "## Predict brain deep sleep slow oscillation, by Dreem\n",
    "### In this challenge, data consists on EEG signals acquired on the Dreem headband in sham condition i.e. without any kind of sound stimulations. Thus we aim to predict brain activity in normal condition.\n",
    "### Goals: In this dataset, we try to predict whether or not a slow oscillation will be followed by another one in sham condition, i.e. without any stimulation. This will allow to:\n",
    "#### Predict normal brain activity\n",
    "#### Know when it’s interesting to stimulate\n",
    "#### Better quantify the impact of an individual stimulation by comparing to what would have occurred without stimulation.\n",
    "\n",
    "###  Found on : https://challengedata.ens.fr/professors/challenges/10/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6eb72c",
   "metadata": {},
   "source": [
    "##  Benchmark code\n",
    "#### Updated to reflect changes in the packages \n",
    "#### Comments added for readabilitiy and interpretation\n",
    "#### Model evaluated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3475a7fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Change working directory\u001b[39;00m\n\u001b[1;32m      3\u001b[0m os\u001b[38;5;241m.\u001b[39mchdir(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/mickey.rice/Desktop/Practice_Python\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mh5py\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Change working directory\n",
    "os.chdir(\"/Users/mickey.rice/Desktop/Practice_Python\")\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef0117a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Trouble shooting\n",
    "# pip install --upgrade --force-reinstall scipy\n",
    "# pip install numba --upgrade\n",
    "# pip install scikit-learn==1.0.2\n",
    "# pip install numpy==1.23\n",
    "# pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cc5495",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with h5py.File(\"X_train.h5\", \"r\") as X_train, h5py.File(\"X_test.h5\", \"r\") as X_test:\n",
    "    #y_train = pd.read_csv(\"y_train_2.csv\").values[:, 1].squeeze()\n",
    "\n",
    "    ## Load data sets    \n",
    "X_train = h5py.File(\"X_train.h5\", \"r\")\n",
    "y_train = pd.read_csv(\"y_train_2.csv\").values[:, 1].squeeze()\n",
    "X_test = h5py.File(\"X_test.h5\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6774246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract features\n",
    "def extract_features(h5):\n",
    "    data = h5[\"features\"][:]\n",
    "    features = []\n",
    "    features.append(data[:, :11])\n",
    "    features.append(data[:, 11:].max(1).reshape(-1, 1))\n",
    "    features.append(data[:, 11:].min(1).reshape(-1, 1))\n",
    "    features.append(np.abs(data[:, 11:]).mean(1).reshape(-1, 1))\n",
    "    features = np.concatenate(features, 1)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32cd06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train\n",
    "features_train = extract_features(X_train)\n",
    "\n",
    "## Test\n",
    "features_test = extract_features(X_test)\n",
    "\n",
    "# Train the model \n",
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "clf.fit(features_train, y_train)\n",
    "\n",
    "# Make Predictions\n",
    "y_pred = clf.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae46ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Predictions to CSV\n",
    "with open(\"y_benchmark.csv\", \"w\") as f:\n",
    "    f.write(\"id,label\\n\" + \"\\n\".join([\"{},{}\".format(i, y) for i, y in enumerate(y_pred)]))\n",
    "\n",
    "# Load `y_test` from the supplementary file\n",
    "y_test = pd.read_csv(\"y_lol_2.csv\").values[:, 1].squeeze()\n",
    "\n",
    "# Evaluate Performance\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "logloss = log_loss(y_test, clf.predict_proba(features_test))\n",
    "auc = roc_auc_score(y_test, clf.predict_proba(features_test), multi_class=\"ovr\")\n",
    "\n",
    "print(f\"✅ Accuracy: {accuracy:.4f}\")\n",
    "print(f\"✅ Log Loss: {logloss:.4f}\")\n",
    "print(f\"✅ AUC: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161fa06a",
   "metadata": {},
   "source": [
    "## Try to improve over the benchmark code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd855c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution in y_train: [114032  78620  68982]\n",
      "Class Distribution in y_test: [79541 78942 79883]\n"
     ]
    }
   ],
   "source": [
    "## Check class balance\n",
    "print(\"Class Distribution in y_train:\", np.bincount(y_train))\n",
    "print(\"Class Distribution in y_test:\", np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b4dd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Improve feature extraction\n",
    "def extract_features(h5):\n",
    "    data = h5[\"features\"][:]\n",
    "    features = []\n",
    "    features.append(data[:, :11])  # First 11 features\n",
    "    features.append(data[:, 11:].max(1).reshape(-1, 1))  # Max\n",
    "    features.append(data[:, 11:].min(1).reshape(-1, 1))  # Min\n",
    "    features.append(np.abs(data[:, 11:]).mean(1).reshape(-1, 1))  # Mean\n",
    "    features.append(np.abs(data[:, 11:]).var(1).reshape(-1, 1))  # Variance (New)\n",
    "    features.append(np.median(data[:, 11:], axis=1).reshape(-1, 1))  # Median (New)\n",
    "    features = np.concatenate(features, 1)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43c9f964",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train features\n",
    "features_train = extract_features(X_train)\n",
    "\n",
    "## Test features\n",
    "features_test = extract_features(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cce177b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add polynomial interactions\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True)  # Only interaction terms\n",
    "features_train_poly = poly.fit_transform(features_train)\n",
    "features_test_poly = poly.transform(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed7cb46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Improve Random Forest incorporating balanced classes, more complex \n",
    "clf = RandomForestClassifier(n_estimators=200, max_depth=20, min_samples_split=10,\n",
    "                             min_samples_leaf=5, class_weight=\"balanced\", random_state=42)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "features_train_poly_scaled = scaler.fit_transform(features_train_poly)\n",
    "features_test_poly_scaled = scaler.transform(features_test_poly)\n",
    "\n",
    "clf.fit(features_train_poly_scaled, y_train)\n",
    "\n",
    "# Make Predictions\n",
    "y_pred = clf.predict(features_test_poly_scaled )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "819d2fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Accuracy: 0.3322\n",
      "✅ Log Loss: 1.1985\n",
      "✅ AUC: 0.4990\n"
     ]
    }
   ],
   "source": [
    "# Load `y_test` from the supplementary file\n",
    "y_test = pd.read_csv(\"y_lol_2.csv\").values[:, 1].squeeze()\n",
    "\n",
    "# Evaluate new performance\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "logloss = log_loss(y_test, clf.predict_proba(features_test_poly_scaled))\n",
    "auc = roc_auc_score(y_test, clf.predict_proba(features_test_poly_scaled), multi_class=\"ovr\")\n",
    "\n",
    "print(f\"✅ Accuracy: {accuracy:.4f}\")\n",
    "print(f\"✅ Log Loss: {logloss:.4f}\")\n",
    "print(f\"✅ AUC: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cbb77a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
